import io
import logging
import os
import platform
import re
from datetime import timedelta
from typing import List
from urllib.parse import urlparse

from speasy import __version__
from speasy.core.cache import CacheCall
from . import http

log = logging.getLogger(__name__)

USER_AGENT = f'Speasy/{__version__} {platform.uname()} (SciQLop project)'

DEFAULT_TIMEOUT = 60  # seconds

DEFAULT_DELAY = 5  # seconds

DEFAULT_RETRY_COUNT = 5

STATUS_FORCE_LIST = [500, 502, 504, 413, 429, 503]

RETRY_AFTER_LIST = [429, 503]  # Note: Specific treatment for 429 & 503 error codes (see below)

_HREF_REGEX = re.compile(' href="([A-Za-z0-9.-_]+)">')


class AnyFile(io.IOBase):
    def __init__(self, url, file_impl: io.IOBase, status=200):
        self._url = url
        self._file_impl = file_impl
        self._status = status

    @property
    def url(self):
        return self._url

    def read(self, *args, **kwargs):
        return self._file_impl.read(*args, **kwargs)

    def seek(self, *args, **kwargs):
        return self._file_impl.seek(*args, **kwargs)

    @property
    def ok(self):
        return (self._status in (200, 304)) and self._file_impl.readable()

    @property
    def status_code(self):
        return self._status

    def __getattr__(self, item):
        return getattr(self._file_impl, item)



def any_loc_open(url, timeout: int = DEFAULT_TIMEOUT, headers: dict = None, mode='rb'):
    split_url = urlparse(url)
    if split_url.scheme in ('', 'file'):
        return AnyFile(url, open(split_url.path, mode=mode))
    else:
        resp = http.urlopen(url=url, headers=headers, timeout=timeout)
        if 'b' in mode:
            return AnyFile(url, io.BytesIO(resp.bytes))
        else:
            return AnyFile(url, io.StringIO(resp.text))


def _list_local_files(path: str) -> List[str]:
    return os.listdir(path)


@CacheCall(cache_retention=timedelta(hours=12), is_pure=True)
def _list_remote_files(url: str) -> List[str]:
    response = http.get(url)
    if response.ok:
        return _HREF_REGEX.findall(response.text)
    return []


def list_files(url: str, file_regex: re.Pattern) -> List[str]:
    """If url scheme is WEB then Lists matching downloadable files inside an html page generated by Apache mod_dir or equivalent, else if url scheme is local files it will list matching files in given path.

    Parameters
    ----------
    url : str
        WEB url or local path to scan
    file_regex : re.Pattern
        regex used to filter files

    Returns
    -------
    List[str]
        matching remote or local files
    """
    split_url = urlparse(url)
    if split_url.scheme in ('', 'file'):
        files = _list_local_files(split_url.path)
    else:
        files = _list_remote_files(url)
    return list(filter(file_regex.match, files))
